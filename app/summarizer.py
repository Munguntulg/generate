#!/usr/bin/env python3
"""
SLM Summarizer - –£–¢–ì–ê –•–ê–î–ì–ê–õ–ê–• —Å–∞–π–∂—Ä—É—É–ª–∞–ª—Ç
“Æ–Ω–¥—Å—ç–Ω ”©”©—Ä—á–ª”©–ª—Ç:
1. Prompt –∏–ª“Ø“Ø —Ç–æ–¥–æ—Ä—Ö–æ–π - –ê–ì–£–£–õ–ì–ê ”®”®–†–ß–õ”®–•–ì“Æ–ô
2. –£—Ç–≥—ã–Ω —à–∞–ª–≥–∞–ª—Ç –Ω—ç–º—ç—Ö
3. Sentence-level –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞–ª—Ç
"""

import re
from typing import Dict, Optional, Tuple, List

try:
    from ollama import chat
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False

# –ó”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–≥—á
try:
    from .spell_checker import MongolianSpellChecker
    SPELL_CHECKER_AVAILABLE = True
except ImportError:
    SPELL_CHECKER_AVAILABLE = False
    print("‚ö†Ô∏è spell_checker.py –±–∞–π—Ö–≥“Ø–π")


class SLMOnlySummarizer:
    """
    –£–¢–ì–ê –•–ê–î–ì–ê–õ–î–ê–ì summarizer
    """
    
    def __init__(self, model: str = "qwen2.5:7b", use_spell_check: bool = True):
        self.model = model
        self.max_chunk_length = 1500
        self.use_spell_check = use_spell_check and SPELL_CHECKER_AVAILABLE
        
        if not OLLAMA_AVAILABLE:
            raise RuntimeError(
                "‚ùå Ollama —Å—É—É–ª–≥–∞–∞–≥“Ø–π –±–∞–π–Ω–∞!\n"
                "   –°—É—É–ª–≥–∞—Ö: pip install ollama"
            )
        
        if self.use_spell_check:
            try:
                self.spell_checker = MongolianSpellChecker()
                print("‚úÖ –ó”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–≥—á –∏–¥—ç–≤—Ö—Ç—ç–π")
            except Exception as e:
                print(f"‚ö†Ô∏è –ó”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–≥—á —ç—Ö–ª—ç—Ö–≥“Ø–π: {e}")
                self.use_spell_check = False
        
        self._verify_model()
        print(f"‚úÖ SLM –±—ç–ª—ç–Ω: {self.model}")
    
    def _verify_model(self):
        """Model —à–∞–ª–≥–∞—Ö"""
        try:
            response = chat(
                model=self.model,
                messages=[{'role': 'user', 'content': 'test'}],
                options={'num_predict': 5}
            )
        except Exception as e:
            error_msg = str(e).lower()
            
            if 'not found' in error_msg or '404' in error_msg:
                raise RuntimeError(
                    f"‚ùå Model '{self.model}' –æ–ª–¥—Å–æ–Ω–≥“Ø–π!\n"
                    f"   –¢–∞—Ç–∞—Ö: ollama pull {self.model}"
                )
            else:
                raise RuntimeError(
                    f"‚ùå Ollama server –∞–∂–∏–ª–ª–∞—Ö–≥“Ø–π –±–∞–π–Ω–∞!\n"
                    f"   –≠—Ö–ª“Ø“Ø–ª—ç—Ö: ollama serve"
                )
    
    def formalize_text(self, text: str, debug: bool = True) -> str:
        """
        –ê–ì–£–£–õ–ì–ê –•–ê–î–ì–ê–õ–°–ê–ù –∞–ª–±–∞–Ω —Ö—ç–ª –±–æ–ª–≥–æ—Ö
        """
        if not OLLAMA_AVAILABLE:
            raise RuntimeError("‚ùå SLM –∞–∂–∏–ª–ª–∞—Ö–≥“Ø–π –±–∞–π–Ω–∞")
        
        # –ó”©–≤ –±–∏—á–≥–∏–π–Ω —É—Ä—å–¥—á–∏–ª—Å–∞–Ω —à–∞–ª–≥–∞–ª—Ç
        if self.use_spell_check:
            if debug:
                print("\nüìù –ó”©–≤ –±–∏—á–≥–∏–π–Ω —É—Ä—å–¥—á–∏–ª—Å–∞–Ω —à–∞–ª–≥–∞–ª—Ç —Ö–∏–π–∂ –±–∞–π–Ω–∞...")
            text = self.spell_checker.integrate_with_summarizer(text)
        
        if len(text) > self.max_chunk_length:
            return self._process_long_text(text)
        
        # –®–ò–ù–≠–ß–ò–õ–°–≠–ù PROMPT - –ê–ì–£–£–õ–ì–ê ”®”®–†–ß–õ”®–•–ì“Æ–ô
        system_prompt = """–¢–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª –∑–∞—Å–≤–∞—Ä–ª–∞–≥—á. –Ø–≥ –Ω—ç–≥ –∑“Ø–π–ª —Ö–∏–π–Ω—ç: –Ø—Ä–∏–∞–Ω—ã –º–∞—è–≥–∏–π–≥ –∞–ª–±–∞–Ω –º–∞—è–≥ –±–æ–ª–≥–æ–Ω–æ.

üéØ –•–ê–ú–ì–ò–ô–ù –ß–£–•–ê–õ: –ê–ì–£–£–õ–ì–ê ”®”®–†–ß–õ”®–•–ì“Æ–ô
- –ù—ç—Ä ‚Üí –Ω—ç—Ä (”©”©—Ä—á–ª”©—Ö–≥“Ø–π)
- –û–≥–Ω–æ–æ ‚Üí –æ–≥–Ω–æ–æ (”©”©—Ä—á–ª”©—Ö–≥“Ø–π)
- –¢–æ–æ ‚Üí —Ç–æ–æ (”©”©—Ä—á–ª”©—Ö–≥“Ø–π)
- “Æ–π–ª ‚Üí “Ø–π–ª (”©”©—Ä—á–ª”©—Ö–≥“Ø–π)
- –ó”©–≤—Ö”©–Ω –•–≠–õ–õ–≠–ì “Æ–ì–° –∞—Ä–∏–ª–≥–∞–Ω–∞

üìù –Ø–†–ò–ê–ù–´ –ú–ê–Ø–ì ‚Üí –ê–õ–ë–ê–ù –ú–ê–Ø–ì:

1. –•—ç–ª–ª—ç–≥ “Ø–≥—Å –ê–†–ò–õ–ì–ê:
   - —à“Ø“Ø –¥—ç—ç, –ª –±–∞–π—Ö –¥–∞–∞, –±–∞–π—Ö–∞–∞ ‚Üí (—É—Å—Ç–≥–∞—Ö)
   - –∑–∞, —Ç—ç–≥—ç—ç–¥, –≥—ç—ç–¥ ‚Üí (—É—Å—Ç–≥–∞—Ö)

2. “Æ–π–ª “Ø–≥ –∞–ª–±–∞–Ω —Ö—ç–ª –±–æ–ª–≥–æ:
   - "–±–∏ —Ö–∏–π–Ω—ç" ‚Üí "[–ù—ç—Ä] –≥“Ø–π—Ü—ç—Ç–≥—ç–Ω—ç"
   - "–±–∏ –±—ç–ª–¥–Ω—ç" ‚Üí "[–ù—ç—Ä] –±—ç–ª—Ç–≥—ç–Ω—ç"
   - "–±–æ–ª–Ω–æ" ‚Üí "–±–æ–ª–æ–≤"
   
3. –ó”©–≤ –±–∏—á–≥–∏–π–Ω –¥“Ø—Ä—ç–º:
   - ”®–≥“Ø“Ø–ª–±—ç—Ä —ç—Ö–Ω–∏–π “Ø—Å—ç–≥ —Ç–æ–º
   - –¢–∞—Å–ª–∞–ª—ã–Ω ”©–º–Ω”© –∑–∞–π –ë–ê–ô–•–ì“Æ–ô
   - –î–∞–≤—Ö–∞—Ä –∑–∞–π –ë–ê–ô–•–ì“Æ–ô

‚ö†Ô∏è –•–û–†–ò–û–¢–û–ô:
- “Æ–≥ —Å–æ–ª–∏—Ö–≥“Ø–π (–ê–Ω–Ω–∞ ‚Üí –ñ–æ–Ω –ë–ò–®–Ü)
- –û–≥–Ω–æ–æ ”©”©—Ä—á–ª”©—Ö–≥“Ø–π (–¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥ ‚Üí —É—Ç–≥–∞ –∞–ª–¥–∞—Ö–≥“Ø–π)
- –¢–æ–æ ”©”©—Ä—á–ª”©—Ö–≥“Ø–π
- –ù—ç–º—ç–ª—Ç —Ç–∞–π–ª–±–∞—Ä –ë–ê–ô–•–ì“Æ–ô
- –ê–Ω–≥–ª–∏ —Ö—ç–ª –ë–ê–ô–•–ì“Æ–ô

–ñ–ò–®–≠–≠:

–Ø—Ä–∏–∞–Ω—ã —Ö—ç–ª:
"–ê–Ω–Ω–∞: –ë–∏ —ç–Ω—ç —Ç”©—Å–ª–∏–π–≥ –¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥—Ç –¥—É—É—Å–≥–∞—Ö –±–æ–ª–Ω–æ —à“Ø“Ø –¥—ç—ç."

–ê–ª–±–∞–Ω —Ö—ç–ª:
"–ê.–ê–Ω–Ω–∞ —É–≥ —Ç”©—Å–ª–∏–π–≥ –¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥—Ç –¥—É—É—Å–≥–∞—Ö –±–æ–ª–æ–≤."

–ê–ù–•–ê–ê–†: "—ç–Ω—ç —Ç”©—Å”©–ª" ‚Üí "—É–≥ —Ç”©—Å”©–ª" (—É—Ç–≥–∞ –∞–¥–∏–ª)
–ê–ù–•–ê–ê–†: "–¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥" ‚Üí "–¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥" (”©”©—Ä—á–ª”©—Ö–≥“Ø–π)"""

        user_prompt = f"""–≠–Ω—ç —è—Ä–∏–∞–Ω—ã –±–∏—á–ª—ç–≥–∏–π–≥ –∞–ª–±–∞–Ω –ø—Ä–æ—Ç–æ–∫–æ–ª –±–æ–ª–≥–æ. –ê–ì–£–£–õ–ì–ê ”®”®–†–ß–õ”®–•–ì“Æ–ô.

–Ø–†–ò–ê–ù–´ –ë–ò–ß–õ–≠–ì:
{text}

–ó”®–í–•”®–ù –∞–ª–±–∞–Ω –º–∞—è–≥ –±–∏—á. –ê–≥—É—É–ª–≥–∞ –±“Ø—Ä—ç–Ω —Ö–∞–¥–≥–∞–ª."""

        try:
            if debug:
                print(f"\n   üì§ SLM —Ä“Ø“Ø —Ö“Ø—Å—ç–ª—Ç –∏–ª–≥—ç—ç–∂ –±–∞–π–Ω–∞...")
                print(f"   –ú–æ–¥–µ–ª—å: {self.model}")
                print(f"   –£—Ä—Ç: {len(text)} —Ç—ç–º–¥—ç–≥—Ç")
            
            response = chat(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                options={
                    "temperature": 0.1,  # 0.05 ‚Üí 0.1 (–∏–ª“Ø“Ø creative)
                    "top_p": 0.9,       # 0.7 ‚Üí 0.9
                    "num_predict": 2000,
                    "repeat_penalty": 1.1,
                }
            )
            
            result = response["message"]["content"].strip()
            
            if debug:
                print(f"\n   üì• SLM —Ö–∞—Ä–∏—É–ª—Ç –∏—Ä–ª—ç—ç ({len(result)} —Ç—ç–º–¥—ç–≥—Ç)")
            
            # Post-processing
            cleaned = self._aggressive_postprocess(result)
            
            # –£–¢–ì–´–ù –®–ê–õ–ì–ê–õ–¢ - –®–ò–ù–≠!
            is_meaningful = self._check_meaning_preserved(text, cleaned)
            
            if not is_meaningful:
                print(f"\n   ‚ö†Ô∏è –ê–ù–•–ê–ê–†–£–£–õ–ì–ê: –£—Ç–≥–∞ –∞–ª–¥–∞–≥–¥—Å–∞–Ω –±–∞–π–∂ –º–∞–≥–∞–¥–≥“Ø–π!")
                print(f"   üîÑ –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–∂ –±–∞–π–Ω–∞ (–∏–ª“Ø“Ø –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤)...")
                
                retry_result = self._retry_formalize_conservative(text, system_prompt, user_prompt)
                if retry_result:
                    cleaned = retry_result
            
            # –ó”©–≤ –±–∏—á–≥–∏–π–Ω —ç—Ü—Å–∏–π–Ω —à–∞–ª–≥–∞–ª—Ç
            if self.use_spell_check:
                if debug:
                    print(f"   üîç –≠—Ü—Å–∏–π–Ω –∑”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–ª—Ç...")
                
                final_check = self.spell_checker.check_text(cleaned, verbose=False)
                
                if final_check['errors']:
                    if debug:
                        print(f"   ‚ö†Ô∏è {len(final_check['errors'])} –∞–ª–¥–∞–∞ –∑–∞—Å–∞–≥–¥–∞–∂ –±–∞–π–Ω–∞")
                    cleaned = final_check['corrected_text']
                else:
                    if debug:
                        print(f"   ‚úÖ –ó”©–≤ –±–∏—á–∏–≥ —Ö–∞–Ω–≥–∞–≥–¥—Å–∞–Ω")
            
            # –≠—Ü—Å–∏–π–Ω validation
            is_valid, errors = self._validate_result_flexible(text, cleaned)
            
            if not is_valid:
                if debug:
                    print(f"\n   ‚ö†Ô∏è Validation:")
                    for error in errors[:3]:
                        print(f"      ‚Ä¢ {error}")
            else:
                if debug:
                    print(f"   ‚úÖ –ß–∞–Ω–∞—Ä —Ö–∞–Ω–≥–∞–ª—Ç—Ç–∞–π")
            
            return cleaned
            
        except Exception as e:
            if isinstance(e, RuntimeError):
                raise
            else:
                raise RuntimeError(
                    f"‚ùå SLM –∞–ª–¥–∞–∞!\n"
                    f"   Model: {self.model}\n"
                    f"   –ê–ª–¥–∞–∞: {str(e)}"
                )
    
    def _check_meaning_preserved(self, original: str, formalized: str) -> bool:
        """
        –£–¢–ì–ê –•–ê–î–ì–ê–õ–ê–ì–î–°–ê–ù —ç—Å—ç—Ö —à–∞–ª–≥–∞—Ö
        
        –®–∞–ª–≥–∞—Ö –∑“Ø–π–ª—Å:
        1. “Æ–Ω–¥—Å—ç–Ω “Ø–≥ –±–∞–π–≥–∞–∞ —ç—Å—ç—Ö (–Ω—ç—Ä, –æ–≥–Ω–æ–æ)
        2. –£—Ç–≥–∞–≥“Ø–π ”©–≥“Ø“Ø–ª–±—ç—Ä “Ø“Ø—Å—Å—ç–Ω —ç—Å—ç—Ö
        3. –•—ç—Ç –±–æ–≥–∏–Ω–æ –±–æ–ª–æ–æ–≥“Ø–π —ç—Å—ç—Ö
        """
        # 1. –ù—ç—Ä—Å —Ö–∞–¥–≥–∞–ª–∞–≥–¥—Å–∞–Ω —ç—Å—ç—Ö
        original_names = re.findall(r'\b[–ê-–Ø–Å“Æ”®][–∞-—è—ë“Ø”©]{2,}\b', original)
        formalized_names = re.findall(r'\b[–ê-–Ø–Å“Æ”®][–∞-—è—ë“Ø”©]{2,}\b', formalized)
        
        # “Æ–Ω–¥—Å—ç–Ω –Ω—ç—Ä—Å –∞–ª–≥–∞ –±–æ–ª—Å–æ–Ω —ç—Å—ç—Ö
        important_names = set(original_names[:10])  # –≠—Ö–Ω–∏–π 10 –Ω—ç—Ä
        preserved_names = set(formalized_names)
        
        missing_names = important_names - preserved_names
        if len(missing_names) > len(important_names) * 0.5:
            print(f"      ‚ö†Ô∏è –û–ª–æ–Ω –Ω—ç—Ä –∞–ª–¥–∞–≥–¥—Å–∞–Ω: {missing_names}")
            return False
        
        # 2. –û–≥–Ω–æ–æ, —Ö—É–≥–∞—Ü–∞–∞ —Ö–∞–¥–≥–∞–ª–∞–≥–¥—Å–∞–Ω —ç—Å—ç—Ö
        date_patterns = [
            r'–¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥', r'–º—è–≥–º–∞—Ä –≥–∞—Ä–∞–≥', r'–ª—Ö–∞–≥–≤–∞ –≥–∞—Ä–∞–≥',
            r'–¥–æ–ª–æ–æ —Ö–æ–Ω–æ–≥', r'—Å–∞—Ä', r'”©–¥”©—Ä', r'–∂–∏–ª',
            r'\d+', r'–Ω—ç–≥', r'—Ö–æ—ë—Ä', r'–≥—É—Ä–∞–≤'
        ]
        
        original_has_dates = any(re.search(pattern, original, re.IGNORECASE) for pattern in date_patterns)
        formalized_has_dates = any(re.search(pattern, formalized, re.IGNORECASE) for pattern in date_patterns)
        
        if original_has_dates and not formalized_has_dates:
            print(f"      ‚ö†Ô∏è –û–≥–Ω–æ–æ/—Ö—É–≥–∞—Ü–∞–∞ –∞–ª–¥–∞–≥–¥—Å–∞–Ω")
            return False
        
        # 3. –£—Ç–≥–∞–≥“Ø–π ”©–≥“Ø“Ø–ª–±—ç—Ä —ç—Å—ç—Ö
        # "–•—ç–¥“Ø“Ø–ª—ç—Ö —Ç”©—Å–ª–∏–π–≥" –≥—ç—Ö –º—ç—Ç —É—Ç–≥–∞–≥“Ø–π “Ø–≥
        nonsense_patterns = [
            r'—Ö—ç–¥“Ø“Ø–ª—ç—Ö',  # –£—Ç–≥–∞–≥“Ø–π “Ø–π–ª “Ø–≥
            r'[–∞-—è—ë“Ø”©]{15,}',  # –•—ç—Ç —É—Ä—Ç —É—Ç–≥–∞–≥“Ø–π “Ø–≥
            r'\b[–∞-—è—ë“Ø”©]\b\s+\b[–∞-—è—ë“Ø”©]\b\s+\b[–∞-—è—ë“Ø”©]\b',  # "–∞ –± –≤" –≥—ç—Ö –º—ç—Ç
        ]
        
        for pattern in nonsense_patterns:
            if re.search(pattern, formalized):
                print(f"      ‚ö†Ô∏è –£—Ç–≥–∞–≥“Ø–π ”©–≥“Ø“Ø–ª–±—ç—Ä –∏–ª—ç—Ä—Å—ç–Ω: {pattern}")
                return False
        
        # 4. –•—ç—Ç –±–æ–≥–∏–Ω–æ —ç—Å—ç—Ö
        ratio = len(formalized) / len(original) if len(original) > 0 else 0
        if ratio < 0.3:  # 30%-—Å –±–∞–≥–∞ –±–æ–ª —Ö—ç—Ç –±–æ–≥–∏–Ω–æ
            print(f"      ‚ö†Ô∏è –•—ç—Ç –±–æ–≥–∏–Ω–æ –±–æ–ª—Å–æ–Ω (—Ö–∞—Ä—å—Ü–∞–∞: {ratio:.2f})")
            return False
        
        return True
    
    def _retry_formalize_conservative(
        self,
        text: str,
        system_prompt: str,
        user_prompt: str
    ) -> Optional[str]:
        """
        –ö–û–ù–°–ï–†–í–ê–¢–ò–í retry - –∞–≥—É—É–ª–≥–∞ –∏–ª“Ø“Ø —Ö–∞–¥–≥–∞–ª–Ω–∞
        """
        try:
            # –ò–ª“Ø“Ø —Ç–æ–¥–æ—Ä—Ö–æ–π –∞–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞
            conservative_prompt = user_prompt + """

üö® –ß–£–•–ê–õ –ê–ù–•–ê–ê–†–£–£–õ–ì–ê:
1. –ù—ç—Ä “Ø–≥—Å –ë“Æ–†–≠–ù —Ö–∞–¥–≥–∞–ª (–ê–Ω–Ω–∞ ‚Üí –ê.–ê–Ω–Ω–∞, —É—Ç–≥–∞ –∏–∂–∏–ª)
2. –û–≥–Ω–æ–æ –ë“Æ–†–≠–ù —Ö–∞–¥–≥–∞–ª (–¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥ ‚Üí –¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥)
3. –¢–æ–æ –ë“Æ–†–≠–ù —Ö–∞–¥–≥–∞–ª
4. “Æ–π–ª “Ø–≥–∏–π–Ω —É—Ç–≥–∞ —Ö–∞–¥–≥–∞–ª (–¥—É—É—Å–≥–∞—Ö ‚Üí –¥—É—É—Å–≥–∞—Ö)
5. –ó”®–í–•”®–ù —Ö—ç–ª–ª—ç–≥ “Ø–≥—Å –∞—Ä–∏–ª–≥–∞

“Æ–≥ —Å–æ–ª–∏—Ö–≥“Ø–π, —É—Ç–≥—ã–≥ –∞–ª–¥–∞—Ö–≥“Ø–π!"""
            
            response = chat(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conservative_prompt}
                ],
                options={
                    "temperature": 0.05,  # –ò–ª“Ø“Ø –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤
                    "top_p": 0.7,
                    "num_predict": 2000,
                    "repeat_penalty": 1.15,
                }
            )
            
            result = response["message"]["content"].strip()
            cleaned = self._aggressive_postprocess(result)
            
            # –î–∞—Ö–∏–Ω —É—Ç–≥—ã–Ω —à–∞–ª–≥–∞–ª—Ç
            is_meaningful = self._check_meaning_preserved(text, cleaned)
            
            if is_meaningful:
                print(f"   ‚úÖ Retry –∞–º–∂–∏–ª—Ç—Ç–∞–π - —É—Ç–≥–∞ —Ö–∞–¥–≥–∞–ª–∞–≥–¥—Å–∞–Ω!")
                return cleaned
            else:
                print(f"   ‚ö†Ô∏è Retry —á —É—Ç–≥–∞ –∞–ª–¥—Å–∞–Ω - –∞–Ω—Ö–Ω—ã “Ø—Ä –¥“Ø–Ω–≥ –∞—à–∏–≥–ª–∞–Ω–∞")
                return None
                
        except Exception as e:
            print(f"   ‚ùå Retry –∞–ª–¥–∞–∞: {e}")
            return None
    
    def _aggressive_postprocess(self, text: str) -> str:
        """
        –•“Ø—á—Ç—ç–π post-processing
        """
        # –•—ç–ª–ª—ç–≥ “Ø–≥—Å
        filler_phrases = [
            '—à“Ø“Ø –¥—ç—ç', '–ª –±–∞–π—Ö –¥–∞–∞', '–ª –±–∞–π—Ö', '–±–∞–π—Ö–∞–∞', '–±–∏–∑ –¥—ç—ç', 
            '–∞–∞ –¥—ç—ç', '—à“Ø“Ø –∞–∞', '—ç—ç –¥—ç—ç', '”©”© –¥—ç—ç', '–¥–∞–∞ —à“Ø“Ø',
            '–≥—ç–∂ –±–æ–¥–æ–∂ –±–∞–π–Ω–∞', '–≥—ç–∂ –±–æ–¥–¥–æ–≥', '–≥—ç–∂ “Ø–∑—ç–∂ –±–∞–π–Ω–∞'
        ]
        
        for phrase in sorted(filler_phrases, key=len, reverse=True):
            text = re.sub(
                r'\b' + re.escape(phrase) + r'\b',
                '',
                text,
                flags=re.IGNORECASE
            )
        
        # –ë–æ–≥–∏–Ω–æ —Ö—ç–ª–ª—ç–≥ “Ø–≥—Å
        short_fillers = [
            '—à“Ø“Ø', '–¥—ç—ç', '–¥–∞–∞', '–∞–∞', '—ç—ç', '”©”©', '—é—É', 
            '–≥—ç—ç–¥', '—Ç—ç–≥—ç—ç–¥', '–∑–∞', '—Ç—ç–≥—ç—Ö—ç—ç—Ä', '–±–∞–π—Ö–∞–∞'
        ]
        
        for filler in short_fillers:
            text = re.sub(
                r'\b' + re.escape(filler) + r'\b',
                '',
                text,
                flags=re.IGNORECASE
            )
        
        # –ó”©–≤ –±–∏—á–≥–∏–π–Ω –¥“Ø—Ä–º“Ø“Ø–¥
        text = re.sub(r'\s+([,.!?:;])', r'\1', text)
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        # MARKDOWN –§–û–†–ú–ê–¢–õ–ê–õ–¢ –ê–†–ò–õ–ì–ê–• (–®–ò–ù–≠!)
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # **text** ‚Üí text
        text = re.sub(r'\*([^*]+)\*', r'\1', text)      # *text* ‚Üí text
        text = re.sub(r'^[-‚Ä¢]\s+', '', text, flags=re.MULTILINE)  # - text ‚Üí text
        text = re.sub(r'#{1,6}\s+', '', text)           # # heading ‚Üí heading
        
        # ”®–≥“Ø“Ø–ª–±—ç—Ä —ç—Ö–Ω–∏–π “Ø—Å—ç–≥ —Ç–æ–º
        lines = []
        for line in text.split('\n'):
            line = line.strip()
            if line:
                line = line[0].upper() + line[1:] if len(line) > 1 else line.upper()
                lines.append(line)
        
        return '\n'.join(lines).strip()
    
    def _validate_result_flexible(
        self, 
        original: str, 
        result: str
    ) -> Tuple[bool, List[str]]:
        """
        –£—è–Ω —Ö–∞—Ç–∞–Ω validation
        """
        errors = []
        
        if len(result.strip()) < 10:
            errors.append(f"–•—ç—Ç –±–æ–≥–∏–Ω–æ")
            return False, errors
        
        ratio = len(result) / len(original) if len(original) > 0 else 0
        if ratio < 0.1:
            errors.append(f"–•—ç—Ç –±–æ–≥–∏–Ω–æ (—Ö–∞—Ä—å—Ü–∞–∞ {ratio:.2f})")
        elif ratio > 10.0:
            errors.append(f"–•—ç—Ç —É—Ä—Ç (—Ö–∞—Ä—å—Ü–∞–∞ {ratio:.2f})")
        
        # –ê–Ω–≥–ª–∏ —Ö—ç–ª
        cyrillic_chars = len(re.findall(r'[–ê-–Ø–∞-—è–Å—ë”®”©“Æ“Ø]', result))
        english_chars = len(re.findall(r'[A-Za-z]', result))
        
        if cyrillic_chars > 0 and english_chars > cyrillic_chars * 0.5:
            errors.append(f"–ê–Ω–≥–ª–∏ —Ö—ç–ª –∏—Ö")
        
        # –ö—Ä–∏—Ç–∏–∫ —Ö—ç–ª–ª—ç–≥ “Ø–≥—Å
        critical_fillers = ['—à“Ø“Ø –¥—ç—ç', '–ª –±–∞–π—Ö –¥–∞–∞', '–±–∏–∑ –¥—ç—ç']
        found = [f for f in critical_fillers if f in result.lower()]
        
        if found:
            errors.append(f"–•—ç–ª–ª—ç–≥ “Ø–≥—Å “Ø–ª–¥—Å—ç–Ω: {', '.join(found)}")
        
        has_critical = len(found) > 0
        
        return not has_critical, errors
    
    def _process_long_text(self, text: str) -> str:
        """
        –£—Ä—Ç —Ç–µ–∫—Å—Ç–∏–π–≥ —Ö—ç—Å—ç–≥–ª—ç—Ö
        """
        sentences = [s.strip() + '.' for s in text.split('.') if len(s.strip()) > 20]
        
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) < self.max_chunk_length:
                current_chunk += " " + sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        formalized_chunks = []
        for i, chunk in enumerate(chunks):
            print(f"   üìÑ –•—ç—Å—ç–≥ {i+1}/{len(chunks)} –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∂ –±–∞–π–Ω–∞...")
            formalized = self.formalize_text(chunk, debug=False)
            formalized_chunks.append(formalized)
        
        return "\n\n".join(formalized_chunks)


# –¢–ï–°–¢
if __name__ == "__main__":
    print("\n" + "="*60)
    print("–£–¢–ì–ê –•–ê–î–ì–ê–õ–ê–• SUMMARIZER –¢–ï–°–¢")
    print("="*60 + "\n")
    
    try:
        summarizer = SLMOnlySummarizer(model="qwen2.5:7b", use_spell_check=False)
        
        # –¢–ï–°–¢ 1: –û–≥–Ω–æ–æ—Ç–æ–π
        test1 = """
        –ê–Ω–Ω–∞: –ë–∏ —ç–Ω—ç —Ç”©—Å–ª–∏–π–≥ –¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥—Ç –¥—É—É—Å–≥–∞—Ö –±–æ–ª–Ω–æ —à“Ø“Ø –¥—ç—ç.
        –ñ–æ–Ω: –ó–∞ —Ç—ç–≥—ç—ç–¥ –±–∏ —à–∞–ª–≥–∞–∂ “Ø–∑—å–µ –ª –±–∞–π—Ö –¥–∞–∞.
        """
        
        print("–¢–ï–°–¢ 1: –û–≥–Ω–æ–æ—Ç–æ–π —Ç–µ–∫—Å—Ç")
        print("–û—Ä–æ—Ö:", test1)
        
        result1 = summarizer.formalize_text(test1, debug=True)
        
        print("\n“Æ—Ä –¥“Ø–Ω:", result1)
        
        # "–¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥" —Ö–∞–¥–≥–∞–ª–∞–≥–¥—Å–∞–Ω —ç—Å—ç—Ö —à–∞–ª–≥–∞—Ö
        if "–¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥" in result1.lower():
            print("‚úÖ –û–≥–Ω–æ–æ —Ö–∞–¥–≥–∞–ª–∞–≥–¥—Å–∞–Ω")
        else:
            print("‚ùå –û–≥–Ω–æ–æ –∞–ª–¥–∞–≥–¥—Å–∞–Ω!")
        
        print("\n" + "="*60)
        print("‚úÖ –¢–ï–°–¢ –î–£–£–°–õ–ê–ê\n")
        
    except RuntimeError as e:
        print(f"\n‚ùå –ê–õ–î–ê–ê:\n{e}\n")