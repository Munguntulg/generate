#!/usr/bin/env python3
"""
–ú–æ–Ω–≥–æ–ª —Ö—ç–ª–Ω–∏–π –∑”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–≥—á

–§—É–Ω–∫—Ü“Ø“Ø–¥:
1. “Æ—Å–≥–∏–π–Ω –∞–ª–¥–∞–∞ –∏–ª—Ä“Ø“Ø–ª—ç—Ö
2. –î“Ø—Ä–º–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª ”©–≥”©—Ö
3. –¢–æ–ª—å –±–∏—á–∏–≥ API —Ö–æ–ª–±–æ—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª)
4. –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ –∑–∞—Å–∞—Ö
"""

import re
from typing import List, Dict, Tuple
import requests
from difflib import get_close_matches


class MongolianSpellChecker:
    """
    –ú–æ–Ω–≥–æ–ª —Ö—ç–ª–Ω–∏–π –∑”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–≥—á
    """
    
    def __init__(self):
        # –ó”©–≤ –±–∏—á–≥–∏–π–Ω “Ø–Ω–¥—Å—ç–Ω –¥“Ø—Ä–º“Ø“Ø–¥
        self.rules = self._load_grammar_rules()
        
        # –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ -> –ó”©–≤ —Ö—É–≤–∏–ª–±–∞—Ä
        self.common_mistakes = self._load_common_mistakes()
        
        # –ê–ª–±–∞–Ω “Ø–≥—Å–∏–π–Ω —Ç–æ–ª—å (”©—Ä–≥”©—Ç–≥”©—Ö –±–æ–ª–æ–º–∂—Ç–æ–π)
        self.official_terms = self._load_official_terms()
        
        print("‚úÖ –ó”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–≥—á –±—ç–ª—ç–Ω")
    
    def _load_grammar_rules(self) -> Dict[str, str]:
        """
        –ú–æ–Ω–≥–æ–ª —Ö—ç–ª–Ω–∏–π –∑”©–≤ –±–∏—á–≥–∏–π–Ω –¥“Ø—Ä–º“Ø“Ø–¥
        """
        return {
            "—Ç”©–≥—Å–≥”©–ª_–Ω—å": "–ù—ç—Ä “Ø–≥–∏–π–Ω —Ç”©–≥—Å–≥”©–ª '-–Ω—å' –Ω—å —Å–∞–ª–∞–Ω–≥–∏–¥ –±–∏—á–∏–≥–¥—ç–Ω—ç. –ñ–∏—à—ç—ç: –Ω–æ–º –Ω—å, –≥–∞—Ä –Ω—å",
            "—Ç–∏–π–Ω_–∏–π–Ω": "'—Ç–∏–π–Ω' –±–∏—à '–∏–π–Ω' –≥—ç–∂ –±–∏—á–Ω—ç. –ñ–∏—à—ç—ç: –î–æ—Ä–∂–∏–π–Ω (–î–æ—Ä–∂—Ç–∏–π–Ω –ë–ò–®–Ü)",
            "–±–æ–ª–Ω–æ_–±–æ–ª–æ–≤": "”®–Ω–≥”©—Ä—Å”©–Ω —Ü–∞–≥—Ç '–±–æ–ª–Ω–æ' –±–∏—à '–±–æ–ª–æ–≤' –≥—ç–∂ –±–∏—á–Ω—ç",
            "—Ö–∏–π–Ω—ç_—Ö–∏–π—Ö": "–ò—Ä—ç—ç–¥“Ø–π —Ü–∞–≥—Ç '—Ö–∏–π–Ω—ç' –±–∏—à '—Ö–∏–π—Ö' —ç—Å–≤—ç–ª '–≥“Ø–π—Ü—ç—Ç–≥—ç–Ω—ç'",
            "–±–∞–π–Ω–∞_–±–∞–π–≥–∞–∞": "'–±–∞–π–Ω–∞' –æ–¥–æ–æ “Ø—Ä–≥—ç–ª–∂–∏–ª—Å—ç–Ω, '–±–∞–π–≥–∞–∞' ”©–Ω–≥”©—Ä—Å”©–Ω —Ü–∞–≥",
            "—Ü—ç–≥_—Ç–∞—Å–ª–∞–ª": "”®–≥“Ø“Ø–ª–±—ç—Ä —Ü—ç–≥—ç—ç—Ä —Ç”©–≥—Å”©–Ω”©. –ñ–∏—à—ç—ç –Ω—ç—Ä–ª—ç—Ö —Ç–∞—Å–ª–∞–ª–∞–∞—Ä —Ç—É—Å–≥–∞–∞—Ä–ª–∞–Ω–∞",
            "—Ç–æ–º_–∂–∏–∂–∏–≥": "”®–≥“Ø“Ø–ª–±—ç—Ä —ç—Ö–Ω–∏–π “Ø—Å—ç–≥ —Ç–æ–º. –ù—ç—Ä “Ø–≥ —Ç–æ–º “Ø—Å–≥—ç—ç—Ä —ç—Ö—ç–ª–Ω—ç",
            "—Ö–æ–æ—Å–æ–Ω_–∑–∞–π": "“Æ–≥–∏–π–Ω —Ö–æ–æ—Ä–æ–Ω–¥ –Ω—ç–≥ —Ö–æ–æ—Å–æ–Ω –∑–∞–π –±–∞–π–Ω–∞",
            "—Ç—ç–º–¥—ç–≥—Ç_—Ö–æ–æ—Å–æ–Ω": "–¢–∞—Å–ª–∞–ª, —Ü—ç–≥–∏–π–Ω ”©–º–Ω”© —Ö–æ–æ—Å–æ–Ω –∑–∞–π –ë–ê–ô–•–ì“Æ–ô",
        }
    
    def _load_common_mistakes(self) -> Dict[str, str]:
        """
        –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ -> –ó”©–≤ —Ö—É–≤–∏–ª–±–∞—Ä
        """
        return {
            # –¢”©–≥—Å–≥”©–ª
            "—Ç–∏–π–Ω": "–∏–π–Ω",
            "–±–æ–ª–Ω–æ —à“Ø“Ø": "–±–æ–ª–æ–≤",
            "—Ö–∏–π–Ω—ç —à“Ø“Ø": "–≥“Ø–π—Ü—ç—Ç–≥—ç–Ω—ç",
            "–±–∞–π–Ω–∞ —à“Ø“Ø": "–±–∞–π–≥–∞–∞ —é–º",
            
            # –•—ç–ª–ª—ç–≥ “Ø–≥—Å
            "—à“Ø“Ø –¥—ç—ç": "",
            "–ª –±–∞–π—Ö –¥–∞–∞": "",
            "–±–∞–π—Ö–∞–∞": "",
            "–¥–∞–∞ —à“Ø“Ø": "",
            "–∞–∞ –¥—ç—ç": "",
            
            # –£—Ç–≥–∞–≥“Ø–π “Ø–≥—Å (–®–ò–ù–≠!)
            "—Ö—ç–¥“Ø“Ø–ª—ç—ç": "",
            "—Ö—ç–¥“Ø“Ø–ª—ç—Ö": "",
            
            # “Æ–π–ª “Ø–≥
            "—Ö–∏–π–º–∞–∞—Ä": "—Ö–∏–π—Ö—ç—ç—Ä",
            "–≥“Ø–π—Ü—ç—Ç–≥—ç–º—ç—ç—Ä": "–≥“Ø–π—Ü—ç—Ç–≥—ç—Ö—ç—ç—Ä",
            "–∏—Ä–º—ç—ç—Ä": "–∏—Ä—ç—Ö—ç—ç—Ä",
            
            # –ê–ª–±–∞–Ω “Ø–≥
            "—Ö—É—Ä–∞–ª –±–æ–ª—Å–æ–Ω": "—Ö—É—Ä–∞–ª –∑–æ—Ö–∏–æ–Ω –±–∞–π–≥—É—É–ª–∞–≥–¥—Å–∞–Ω",
            "—è—Ä—å—Å–∞–Ω": "–∏–ª—Ç–≥—ç–ª —Ç–∞–≤—å—Å–∞–Ω",
            "—Ö—ç–ª—Å—ç–Ω": "–¥—ç–≤—à“Ø“Ø–ª—Å—ç–Ω",
            "—à–∏–π–¥—Å—ç–Ω": "—Ç–æ–≥—Ç–æ–æ–ª –≥–∞—Ä–≥–∞—Å–∞–Ω",
        }
    
    def _load_official_terms(self) -> Dict[str, List[str]]:
        """
        –ê–ª–±–∞–Ω —ë—Å–Ω—ã –Ω—ç—Ä —Ç–æ–º—å—ë–æ
        """
        return {
            "—Ö—É—Ä–∞–ª": ["—Ö—É—Ä–∞–ª –∑–æ—Ö–∏–æ–Ω –±–∞–π–≥—É—É–ª–∞—Ö", "—Ö—É—Ä–∞–ª–¥–∞–∞–Ω –∑–æ—Ö–∏–æ–Ω –±–∞–π–≥—É—É–ª–∞—Ö"],
            "–ø—Ä–æ—Ç–æ–∫–æ–ª": ["—Ö—É—Ä–ª—ã–Ω –ø—Ä–æ—Ç–æ–∫–æ–ª", "—Ö—É—Ä–∞–ª–¥–∞–∞–Ω—ã —Ç—ç–º–¥—ç–≥–ª—ç–ª"],
            "—à–∏–π–¥–≤—ç—Ä": ["—Ç–æ–≥—Ç–æ–æ–ª –≥–∞—Ä–≥–∞—Ö", "—à–∏–π–¥–≤—ç—Ä –≥–∞—Ä–≥–∞—Ö"],
            "–∞–∂–∏–ª": ["–∞–∂–∏–ª “Ø“Ø—Ä—ç–≥", "–¥–∞–∞–ª–≥–∞–≤–∞—Ä"],
            "—Ö“Ø–Ω": ["–æ—Ä–æ–ª—Ü–æ–≥—á", "—Ö—É—Ä–∞–ª–¥ –æ—Ä–æ–ª—Ü–æ–≥—á"],
            "—è—Ä–∏—Ö": ["–∏–ª—Ç–≥—ç–ª —Ç–∞–≤–∏—Ö", "—Å–∞–Ω–∞–ª –¥—ç–≤—à“Ø“Ø–ª—ç—Ö"],
            "—Ç–∞–π–ª–∞–Ω": ["—Ç–∞–π–ª–∞–Ω —Ç–∞–Ω–∏–ª—Ü—É—É–ª–∞—Ö", "–º—ç–¥—ç—ç–ª—ç–ª —Ö–∏–π—Ö"],
        }
    
    def check_text(self, text: str, verbose: bool = True) -> Dict:
        """
        –¢–µ–∫—Å—Ç–∏–π–≥ —à–∞–ª–≥–∞–∂ –∞–ª–¥–∞–∞ –∏–ª—Ä“Ø“Ø–ª—ç—Ö
        
        Returns:
            {
                'errors': [],
                'suggestions': [],
                'stats': {},
                'corrected_text': str
            }
        """
        errors = []
        suggestions = []
        
        if verbose:
            print("\n" + "="*60)
            print("–ó”®–í –ë–ò–ß–ì–ò–ô–ù –®–ê–õ–ì–ê–õ–¢")
            print("="*60)
        
        # 1. –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ –∏–ª—Ä“Ø“Ø–ª—ç—Ö
        if verbose:
            print("\n1Ô∏è‚É£ –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ —Ö–∞–π–∂ –±–∞–π–Ω–∞...")
        
        mistake_errors = self._find_common_mistakes(text)
        errors.extend(mistake_errors)
        
        if mistake_errors:
            if verbose:
                print(f"   ‚ùå {len(mistake_errors)} –∞–ª–¥–∞–∞ –æ–ª–¥—Å–æ–Ω")
                for err in mistake_errors[:3]:
                    print(f"      ‚Ä¢ {err}")
        else:
            if verbose:
                print(f"   ‚úÖ –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
        
        # 2. –î“Ø—Ä–º–∏–π–Ω —à–∞–ª–≥–∞–ª—Ç
        if verbose:
            print("\n2Ô∏è‚É£ –î“Ø—Ä–º–∏–π–Ω –¥–∞–≥—É—É —à–∞–ª–≥–∞–∂ –±–∞–π–Ω–∞...")
        
        rule_errors = self._check_grammar_rules(text)
        errors.extend(rule_errors)
        
        if rule_errors:
            if verbose:
                print(f"   ‚ö†Ô∏è {len(rule_errors)} –¥“Ø—Ä–º–∏–π–Ω –∑”©—Ä—á–∏–ª")
        else:
            if verbose:
                print(f"   ‚úÖ “Æ–Ω–¥—Å—ç–Ω –¥“Ø—Ä–º“Ø“Ø–¥ —Ö–∞–Ω–≥–∞–≥–¥—Å–∞–Ω")
        
        # 3. –ê–ª–±–∞–Ω –Ω—ç—Ä —Ç–æ–º—å—ë–æ —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ—Ö
        if verbose:
            print("\n3Ô∏è‚É£ –ê–ª–±–∞–Ω –Ω—ç—Ä —Ç–æ–º—å—ë–æ —à–∞–ª–≥–∞–∂ –±–∞–π–Ω–∞...")
        
        term_suggestions = self._suggest_official_terms(text)
        suggestions.extend(term_suggestions)
        
        if term_suggestions:
            if verbose:
                print(f"   üí° {len(term_suggestions)} —Å–∞–Ω–∞–ª")
        else:
            if verbose:
                print(f"   ‚úÖ –ê–ª–±–∞–Ω “Ø–≥ —Ö–∞–Ω–≥–∞–ª—Ç—Ç–∞–π")
        
        # 4. –ê–≤—Ç–æ–º–∞—Ç –∑–∞—Å–≤–∞—Ä
        corrected_text = self._auto_correct(text)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫
        stats = {
            "original_length": len(text),
            "corrected_length": len(corrected_text),
            "errors_found": len(errors),
            "suggestions_made": len(suggestions),
        }
        
        if verbose:
            print("\n" + "="*60)
            print(f"–î“Ø–≥–Ω—ç–ª—Ç: {len(errors)} –∞–ª–¥–∞–∞, {len(suggestions)} —Å–∞–Ω–∞–ª")
            print("="*60)
        
        return {
            "errors": errors,
            "suggestions": suggestions,
            "stats": stats,
            "corrected_text": corrected_text
        }
    
    def _find_common_mistakes(self, text: str) -> List[str]:
        """
        –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ —Ö–∞–π—Ö
        """
        errors = []
        
        for mistake, correction in self.common_mistakes.items():
            if mistake in text.lower():
                if correction:
                    errors.append(
                        f"'{mistake}' ‚Üí '{correction}' –≥—ç–∂ –±–∏—á–∏—Ö —Ö—ç—Ä—ç–≥—Ç—ç–π"
                    )
                else:
                    errors.append(
                        f"'{mistake}' —Ö—ç–ª–ª—ç–≥ “Ø–≥ –∞—Ä–∏–ª–≥–∞—Ö —Ö—ç—Ä—ç–≥—Ç—ç–π"
                    )
        
        return errors
    
    def _check_grammar_rules(self, text: str) -> List[str]:
        """
        –î“Ø—Ä–º–∏–π–Ω —à–∞–ª–≥–∞–ª—Ç
        """
        errors = []
        
        # ”®–≥“Ø“Ø–ª–±—ç—Ä —ç—Ö–Ω–∏–π “Ø—Å—ç–≥ –∂–∏–∂–∏–≥ –±–∞–π–≤–∞–ª
        sentences = re.split(r'[.!?]\s+', text)
        for sent in sentences:
            if sent and len(sent) > 0:
                if sent[0].islower() and sent[0].isalpha():
                    errors.append(
                        f"”®–≥“Ø“Ø–ª–±—ç—Ä —ç—Ö–Ω–∏–π “Ø—Å—ç–≥ —Ç–æ–º –±–∞–π—Ö: '{sent[:20]}...'"
                    )
        
        # –¢–∞—Å–ª–∞–ª—ã–Ω ”©–º–Ω”© —Ö–æ–æ—Å–æ–Ω –∑–∞–π
        if re.search(r'\s+[,.]', text):
            errors.append("–¢–∞—Å–ª–∞–ª, —Ü—ç–≥–∏–π–Ω ”©–º–Ω”© —Ö–æ–æ—Å–æ–Ω –∑–∞–π –±–∞–π–∂ –±–æ–ª–æ—Ö–≥“Ø–π")
        
        # –î–∞–≤—Ö–∞—Ä —Ö–æ–æ—Å–æ–Ω –∑–∞–π
        if re.search(r'\s{2,}', text):
            errors.append("–î–∞–≤—Ö–∞—Ä —Ö–æ–æ—Å–æ–Ω –∑–∞–π –∞—Ä–∏–ª–≥–∞—Ö —Ö—ç—Ä—ç–≥—Ç—ç–π")
        
        return errors
    
    def _suggest_official_terms(self, text: str) -> List[str]:
        """
        –ê–ª–±–∞–Ω –Ω—ç—Ä —Ç–æ–º—å—ë–æ —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ—Ö
        """
        suggestions = []
        
        for informal, formal_options in self.official_terms.items():
            if informal in text.lower():
                suggestions.append(
                    f"'{informal}' ‚Üí {formal_options[0]} –≥—ç–∂ –±–∏—á–∏—Ö –∏–ª“Ø“Ø –∞–ª–±–∞–Ω —ë—Å–Ω—ã"
                )
        
        return suggestions
    
    def _auto_correct(self, text: str) -> str:
        """
        –ê–≤—Ç–æ–º–∞—Ç –∑–∞—Å–≤–∞—Ä —Ö–∏–π—Ö
        """
        corrected = text
        
        # 1. –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ –∑–∞—Å–∞—Ö
        for mistake, correction in self.common_mistakes.items():
            if correction:  # –•–æ–æ—Å–æ–Ω –±–∏—à –±–æ–ª
                corrected = re.sub(
                    r'\b' + re.escape(mistake) + r'\b',
                    correction,
                    corrected,
                    flags=re.IGNORECASE
                )
            else:  # –ê—Ä–∏–ª–≥–∞—Ö
                corrected = re.sub(
                    r'\b' + re.escape(mistake) + r'\b',
                    '',
                    corrected,
                    flags=re.IGNORECASE
                )
        
        # 2. –¢–∞—Å–ª–∞–ª—ã–Ω ”©–º–Ω”© —Ö–æ–æ—Å–æ–Ω –∑–∞–π –∞—Ä–∏–ª–≥–∞—Ö
        corrected = re.sub(r'\s+([,.])', r'\1', corrected)
        
        # 3. –î–∞–≤—Ö–∞—Ä —Ö–æ–æ—Å–æ–Ω –∑–∞–π
        corrected = re.sub(r'\s+', ' ', corrected)
        
        # 4. ”®–≥“Ø“Ø–ª–±—ç—Ä —ç—Ö–Ω–∏–π “Ø—Å—ç–≥ —Ç–æ–º
        sentences = re.split(r'([.!?]\s+)', corrected)
        capitalized = []
        for i, part in enumerate(sentences):
            if i % 2 == 0 and part:  # –¢–µ–∫—Å—Ç —Ö—ç—Å—ç–≥
                part = part.strip()
                if part:
                    part = part[0].upper() + part[1:] if len(part) > 1 else part.upper()
            capitalized.append(part)
        
        corrected = ''.join(capitalized)
        
        return corrected.strip()
    
    def get_rule_info(self, rule_key: str) -> str:
        """
        –¢–æ–¥–æ—Ä—Ö–æ–π –¥“Ø—Ä–º–∏–π–Ω —Ç–∞–π–ª–±–∞—Ä –∞–≤–∞—Ö
        """
        return self.rules.get(rule_key, "–î“Ø—Ä—ç–º –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
    
    def list_all_rules(self):
        """
        –ë“Ø—Ö –¥“Ø—Ä–º–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
        """
        print("\n" + "="*60)
        print("–ú–û–ù–ì–û–õ –•–≠–õ–ù–ò–ô –ó”®–í –ë–ò–ß–ì–ò–ô–ù –î“Æ–†–ú“Æ“Æ–î")
        print("="*60 + "\n")
        
        for i, (key, rule) in enumerate(self.rules.items(), 1):
            print(f"{i}. {key.upper().replace('_', ' ')}")
            print(f"   {rule}\n")
    
    def integrate_with_summarizer(self, text: str) -> str:
        """
        Summarizer-—Ç—ç–π –Ω—ç–≥—Ç–≥—ç—Ö - –∞–ª–±–∞–Ω —Ö—ç–ª –±–æ–ª–≥–æ—Ö—ã–Ω ”©–º–Ω”© —à–∞–ª–≥–∞—Ö
        """
        print("\nüîç –ó”©–≤ –±–∏—á–≥–∏–π–Ω —É—Ä—å–¥—á–∏–ª—Å–∞–Ω —à–∞–ª–≥–∞–ª—Ç...")
        
        result = self.check_text(text, verbose=False)
        
        if result['errors']:
            print(f"   ‚ö†Ô∏è {len(result['errors'])} –∞–ª–¥–∞–∞ –∏–ª—ç—Ä—Å—ç–Ω")
            print("   üîß –ê–≤—Ç–æ–º–∞—Ç –∑–∞—Å–≤–∞—Ä —Ö–∏–π–∂ –±–∞–π–Ω–∞...")
            return result['corrected_text']
        else:
            print(f"   ‚úÖ –ê–ª–¥–∞–∞ –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
            return text


# ============================================
# –¢–û–õ–¨ –ë–ò–ß–ò–ì API –•–û–õ–ë–û–• (–û–ü–¶–ò–û–ù–ê–õ)
# ============================================

class MongolianDictionary:
    """
    –ú–æ–Ω–≥–æ–ª —Ö—ç–ª–Ω–∏–π —Ç–æ–ª—å –±–∏—á–∏–≥ API
    """
    
    def __init__(self):
        # “Æ–Ω—ç–≥“Ø–π –ú–æ–Ω–≥–æ–ª —Ç–æ–ª—å –±–∏—á–≥–∏–π–Ω API –±–∞–π–≤–∞–ª —Ö–æ–ª–±–æ—Ö
        # –ñ–∏—à—ç—ç: mondict.net, mongoltoli.mn
        self.api_url = None  # –û–¥–æ–æ–≥–æ–æ—Ä API –±–∞–π—Ö–≥“Ø–π
        
        # –õ–æ–∫–∞–ª —Ç–æ–ª—å (–∂–∏–∂–∏–≥ —Ö—É–≤–∏–ª–±–∞—Ä)
        self.local_dict = self._load_local_dictionary()
    
    def _load_local_dictionary(self) -> Dict[str, str]:
        """
        –ñ–∏–∂–∏–≥ –ª–æ–∫–∞–ª —Ç–æ–ª—å
        """
        return {
            "–ø—Ä–æ—Ç–æ–∫–æ–ª": "–ê–ª–±–∞–Ω –±–∞–π–≥—É—É–ª–ª–∞–≥—ã–Ω —Ö—É—Ä–∞–ª–¥–∞–∞–Ω, “Ø–π–ª –∞–∂–∏–ª–ª–∞–≥–∞–∞–Ω—ã —è–≤—Ü—ã–≥ —Ç—ç–º–¥—ç–≥–ª—ç—Å—ç–Ω –±–∞—Ä–∏–º—Ç –±–∏—á–∏–≥",
            "—Ç–æ–≥—Ç–æ–æ–ª": "–ê–ª–±–∞–Ω –±–∞–π–≥—É—É–ª–ª–∞–≥–∞, —Ö—É—Ä–∞–ª–¥–∞–∞–Ω–∞–∞—Ä –≥–∞—Ä–≥–∞—Å–∞–Ω —à–∏–π–¥–≤—ç—Ä",
            "–≥“Ø–π—Ü—ç—Ç–≥—ç—Ö": "–ê–∂–∏–ª, “Ø“Ø—Ä–≥–∏–π–≥ –±–∏–µ–ª“Ø“Ø–ª—ç—Ö",
            "–∏–ª—Ç–≥—ç–ª": "–•—É—Ä–∞–ª, —Ö—ç–ª—ç–ª—Ü“Ø“Ø–ª—ç–≥—Ç —Ö–∏–π—Ö –∞–ª–±–∞–Ω —ë—Å–Ω—ã “Ø–≥ —Ö—ç–ª—ç–ª—Ç",
            "—Ö—É—Ä–∞–ª–¥–∞–∞–Ω": "–¢–æ–¥–æ—Ä—Ö–æ–π –∞—Å—É—É–¥–ª—ã–≥ —Ö—ç–ª—ç–ª—Ü—ç—Ö –∑–æ—Ä–∏–ª–≥–æ–æ—Ä –∑–æ—Ö–∏–æ–Ω –±–∞–π–≥—É—É–ª—Å–∞–Ω —Ü—É–≥–ª–∞–∞–Ω",
        }
    
    def lookup(self, word: str) -> str:
        """
        “Æ–≥–∏–π–Ω —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ–ª—Ç —Ö–∞–π—Ö
        """
        word_lower = word.lower().strip()
        
        if word_lower in self.local_dict:
            return self.local_dict[word_lower]
        
        # API –±–∞–π–≤–∞–ª —ç–Ω–¥ —Ö–æ–ª–±–æ—Ö
        # if self.api_url:
        #     return self._query_api(word)
        
        return f"'{word}' “Ø–≥–∏–π–Ω —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ–ª—Ç –æ–ª–¥—Å–æ–Ω–≥“Ø–π"
    
    def suggest_synonyms(self, word: str) -> List[str]:
        """
        –û–π—Ä–æ–ª—Ü–æ–æ —É—Ç–≥–∞—Ç–∞–π “Ø–≥ —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ—Ö
        """
        synonyms_db = {
            "—Ö–∏–π—Ö": ["–≥“Ø–π—Ü—ç—Ç–≥—ç—Ö", "–±–∏–µ–ª“Ø“Ø–ª—ç—Ö", "—Ö—ç—Ä—ç–≥–∂“Ø“Ø–ª—ç—Ö"],
            "—Ö—ç–ª—ç—Ö": ["–¥—ç–≤—à“Ø“Ø–ª—ç—Ö", "–∏–ª—ç—Ä—Ö–∏–π–ª—ç—Ö", "–∏–ª—Ç–≥—ç—Ö"],
            "—à–∏–π–¥—ç—Ö": ["—Ç–æ–≥—Ç–æ–æ—Ö", "—à–∏–π–¥–≤—ç—Ä–ª—ç—Ö", "–¥“Ø–≥–Ω—ç—Ö"],
            "–∞–∂–∏–ª": ["“Ø“Ø—Ä—ç–≥", "–¥–∞–∞–ª–≥–∞–≤–∞—Ä", "–∞—Å—É—É–¥–∞–ª"],
        }
        
        return synonyms_db.get(word.lower(), [])


# ============================================
# –¢–ï–°–¢–õ–≠–•
# ============================================

def test_spell_checker():
    """
    –ó”©–≤ –±–∏—á–≥–∏–π–Ω —à–∞–ª–≥–∞–≥—á–∏–π–≥ —Ç–µ—Å—Ç–ª—ç—Ö
    """
    checker = MongolianSpellChecker()
    
    # –¢–µ—Å—Ç —Ç–µ–∫—Å—Ç (–∞–ª–¥–∞–∞—Ç–∞–π)
    test_text = """
    –ê–Ω–Ω–∞: –±–∏ —ç–Ω—ç –∞–∂–ª—ã–≥ –¥–∞–≤–∞–∞ –≥–∞—Ä–∞–≥—Ç —Ö–∏–π–Ω—ç —à“Ø“Ø –¥—ç—ç.
    –ñ–æ–Ω: –∑–∞ —Ç—ç–≥—ç—ç–¥   –±–∏ —à–∞–ª–≥–∞–∂ “Ø–∑—å–µ –ª –±–∞–π—Ö –¥–∞–∞ .
    –¢–æ–≥—Ç–æ–æ–ª: –∏—Ä—ç—Ö –¥–æ–ª–æ–æ —Ö–æ–Ω–æ–≥—Ç –¥—É—É—Å–≥–∞—Ö –±–æ–ª–Ω–æ —à“Ø“Ø
    """
    
    print("–ê–ù–•–ù–´ –¢–ï–ö–°–¢:")
    print(test_text)
    
    result = checker.check_text(test_text)
    
    print("\n\n–ó–ê–°–í–ê–†–õ–ê–°–ê–ù –¢–ï–ö–°–¢:")
    print(result['corrected_text'])
    
    # –î“Ø—Ä–º“Ø“Ø–¥ —Ö–∞—Ä–∞—Ö
    print("\n\n")
    checker.list_all_rules()
    
    # –¢–æ–ª—å –±–∏—á–∏–≥ —Ç–µ—Å—Ç
    print("\n" + "="*60)
    print("–¢–û–õ–¨ –ë–ò–ß–ò–ì –¢–ï–°–¢")
    print("="*60 + "\n")
    
    dictionary = MongolianDictionary()
    
    words = ["–ø—Ä–æ—Ç–æ–∫–æ–ª", "—Ç–æ–≥—Ç–æ–æ–ª", "–≥“Ø–π—Ü—ç—Ç–≥—ç—Ö"]
    for word in words:
        definition = dictionary.lookup(word)
        print(f"üìñ {word}: {definition}\n")


if __name__ == "__main__":
    test_spell_checker()