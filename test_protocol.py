#!/usr/bin/env python3
"""
–ü—Ä–æ—Ç–æ–∫–æ–ª “Ø“Ø—Å–≥—ç—Ö —Å–∏—Å—Ç–µ–º–∏–π–≥ —Ç–µ—Å—Ç–ª—ç—Ö —Å–∫—Ä–∏–ø—Ç (SLM-ONLY —Ä–µ–∂–∏–º)
"""

import json
import sys
from pathlib import Path

# –õ–æ–∫–∞–ª –º–æ–¥—É–ª–∏—É–¥—ã–≥ import —Ö–∏–π—Ö
sys.path.insert(0, str(Path(__file__).parent))

from app.preprocess import clean_text, extract_entities
from app.exporter import export_enhanced_protocol
from datetime import date

# SLM-only imports
try:
    from app.summarizer import SLMOnlySummarizer
    from app.action_extractor import SLMOnlyActionExtractor
    SLM_AVAILABLE = True
except ImportError as e:
    print(f"‚ùå SLM –º–æ–¥—É–ª–∏—É–¥ import —Ö–∏–π–≥–¥—Å—ç–Ω–≥“Ø–π: {e}")
    SLM_AVAILABLE = False

# UDPipe (optional)
try:
    from app.nlp_processor import MongolianNLPProcessor
    nlp_processor = MongolianNLPProcessor("mn_model.udpipe")
    print("‚úì UDPipe –º–æ–¥–µ–ª—å –∞—á–∞–∞–ª–∞–≥–¥–ª–∞–∞")
except Exception as e:
    print(f"‚ö† UDPipe –∞—á–∞–∞–ª–∞–≥–¥—Å–∞–Ω–≥“Ø–π: {e}")
    print("  Rule-based extraction –∞—à–∏–≥–ª–∞–Ω–∞")
    nlp_processor = None


def test_with_json_file(json_path: str = "text.json"):
    """
    text.json —Ñ–∞–π–ª–∞–∞—Å —Ç–µ–∫—Å—Ç —É–Ω—à–∏–∂ –ø—Ä–æ—Ç–æ–∫–æ–ª “Ø“Ø—Å–≥—ç—Ö (SLM-ONLY)
    """
    print("\n" + "="*60)
    print("–ü–†–û–¢–û–ö–û–õ “Æ“Æ–°–ì–≠–• –°–ò–°–¢–ï–ú –¢–ï–°–¢ (SLM-ONLY)")
    print("="*60 + "\n")
    
    # SLM —à–∞–ª–≥–∞—Ö
    if not SLM_AVAILABLE:
        print("‚ùå SLM –º–æ–¥—É–ª–∏—É–¥ –±–∞–π—Ö–≥“Ø–π!")
        print("\n–®–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —Ñ–∞–π–ª—É—É–¥ “Ø“Ø—Å–≥—ç—Ö:")
        print("  1. app/summarizer.py")
        print("  2. app/action_extractor.py")
        return
    
    # 1. JSON —Ñ–∞–π–ª —É–Ω—à–∞—Ö
    print("1Ô∏è‚É£  JSON —Ñ–∞–π–ª —É–Ω—à–∏–∂ –±–∞–π–Ω–∞...")
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        raw_text = data.get('text', '')
        
        if not raw_text:
            print("‚ùå –¢–µ–∫—Å—Ç —Ö–æ–æ—Å–æ–Ω –±–∞–π–Ω–∞!")
            return
        
        print(f"   ‚úì –ê–Ω—Ö–Ω—ã —Ç–µ–∫—Å—Ç: {len(raw_text)} —Ç—ç–º–¥—ç–≥—Ç")
        print(f"   –≠—Ö–Ω–∏–π 100 —Ç—ç–º–¥—ç–≥—Ç: {raw_text[:100]}...")
        
    except FileNotFoundError:
        print(f"‚ùå {json_path} —Ñ–∞–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
        return
    except json.JSONDecodeError as e:
        print(f"‚ùå JSON parsing –∞–ª–¥–∞–∞: {e}")
        return
    
    # 2. –¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö
    print("\n2Ô∏è‚É£  –¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç–∂ –±–∞–π–Ω–∞...")
    cleaned_text = clean_text(raw_text)
    print(f"   ‚úì –¶—ç–≤—ç—Ä–ª—ç—Å—ç–Ω —Ç–µ–∫—Å—Ç: {len(cleaned_text)} —Ç—ç–º–¥—ç–≥—Ç")
    
    # 3. –ù—ç—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö
    print("\n3Ô∏è‚É£  –ù—ç—Ä, –±–∞–π–≥—É—É–ª–ª–∞–≥–∞ –∏–ª—Ä“Ø“Ø–ª–∂ –±–∞–π–Ω–∞...")
    if nlp_processor:
        try:
            nlp_result = nlp_processor.process_text(cleaned_text)
            entities = nlp_processor.extract_named_entities(nlp_result)
            print(f"   ‚úì UDPipe: {len(entities)} –Ω—ç—Ä –æ–ª—Å–æ–Ω")
        except Exception as e:
            print(f"   ‚ö† UDPipe –∞–ª–¥–∞–∞: {e}, rule-based –∞—à–∏–≥–ª–∞–Ω–∞")
            entities = extract_entities(cleaned_text)
    else:
        entities = extract_entities(cleaned_text)
        print(f"   ‚úì Rule-based: {len(entities)} –Ω—ç—Ä –æ–ª—Å–æ–Ω")
    
    if entities:
        print(f"   –û–ª—Å–æ–Ω –Ω—ç—Ä—Å: {', '.join(entities[:10])}")
    else:
        print(f"   ‚ö†Ô∏è  –ù—ç—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
    
    # 4. SLM —ç—Ö–ª“Ø“Ø–ª—ç—Ö
    print("\n4Ô∏è‚É£  SLM —Å–∏—Å—Ç–µ–º —ç—Ö–ª“Ø“Ø–ª–∂ –±–∞–π–Ω–∞...")
    try:
        summarizer = SLMOnlySummarizer(model="qwen2.5:7b")
        action_extractor = SLMOnlyActionExtractor(nlp_processor)
        print("   ‚úÖ SLM –±—ç–ª—ç–Ω")
    except RuntimeError as e:
        print(f"\n‚ùå SLM –≠–•–õ“Æ“Æ–õ–≠–• –ê–õ–î–ê–ê:")
        print(f"{e}")
        print("\n‚ùå –¢–ï–°–¢ –ó–û–ì–°–°–û–ù - SLM –∞–∂–∏–ª–ª–∞—Ö–≥“Ø–π –±–∞–π–Ω–∞")
        return
    
    # 5. –ê–ª–±–∞–Ω —Ö—ç–ª –±–æ–ª–≥–æ—Ö
    print("\n5Ô∏è‚É£  –Ø—Ä–∏–∞–Ω—ã —Ö—ç–ª–∏–π–≥ –∞–ª–±–∞–Ω –ø—Ä–æ—Ç–æ–∫–æ–ª –±–æ–ª–≥–æ–∂ –±–∞–π–Ω–∞...")
    print("   (SLM –∞—à–∏–≥–ª–∞–∂ –±–∞–π–≥–∞–∞ —Ç—É–ª —É–¥–∞–∞–Ω –±–æ–ª–∂ –º–∞–≥–∞–¥–≥“Ø–π)")
    
    try:
        formalized_text = summarizer.formalize_text(cleaned_text)
        
        print(f"   ‚úÖ –ê–º–∂–∏–ª—Ç—Ç–∞–π: {len(formalized_text)} —Ç—ç–º–¥—ç–≥—Ç")
        print(f"   “Æ—Ä –¥“Ø–Ω–≥–∏–π–Ω —ç—Ö–ª—ç–ª:\n")
        print("   " + "-"*56)
        for line in formalized_text[:300].split('\n')[:5]:
            print(f"   {line}")
        print("   " + "-"*56)
        
    except RuntimeError as e:
        print(f"\n‚ùå –ê–õ–ë–ê–ù –•–≠–õ –ë–û–õ–ì–û–• –ê–õ–î–ê–ê:")
        print(f"{e}")
        print("\n‚ùå –¢–ï–°–¢ –ó–û–ì–°–°–û–ù")
        return
    
    # 6. Action items –≥–∞—Ä–≥–∞—Ö
    print("\n6Ô∏è‚É£  –ê–∂–∏–ª “Ø“Ø—Ä—ç–≥, —à–∏–π–¥–≤—ç—Ä“Ø“Ø–¥–∏–π–≥ –∏–ª—Ä“Ø“Ø–ª–∂ –±–∞–π–Ω–∞...")
    
    try:
        actions = action_extractor.extract_actions_with_llm(cleaned_text)
        
        print(f"   ‚úÖ {len(actions)} –∞–∂–∏–ª “Ø“Ø—Ä—ç–≥/—à–∏–π–¥–≤—ç—Ä –æ–ª—Å–æ–Ω\n")
        
        for i, action in enumerate(actions[:5], 1):
            print(f"   {i}. {action.get('who', '?')}: {action.get('action', '')[:50]}...")
            print(f"      –•—É–≥–∞—Ü–∞–∞: {action.get('due', '–¢–æ–¥–æ—Ä—Ö–æ–π–≥“Ø–π')}")
        
        if len(actions) > 5:
            print(f"   ... –±–æ–ª–æ–Ω –±—É—Å–∞–¥ {len(actions) - 5}")
        
    except RuntimeError as e:
        print(f"\n‚ùå –ê–ñ–ò–õ “Æ“Æ–†–≠–ì –ò–õ–†“Æ“Æ–õ–≠–• –ê–õ–î–ê–ê:")
        print(f"{e}")
        print("\n‚ùå –¢–ï–°–¢ –ó–û–ì–°–°–û–ù")
        return
    
    # 7. –ü—Ä–æ—Ç–æ–∫–æ–ª –±“Ø—Ç—ç—Ü “Ø“Ø—Å–≥—ç—Ö
    print("\n7Ô∏è‚É£  –ü—Ä–æ—Ç–æ–∫–æ–ª –±“Ø—Ç—ç—Ü “Ø“Ø—Å–≥—ç–∂ –±–∞–π–Ω–∞...")
    
    protocol = {
        "title": "–•—É—Ä–ª—ã–Ω –ø—Ä–æ—Ç–æ–∫–æ–ª",
        "date": str(date.today()),
        "participants": entities if entities else ["–¢–æ–¥–æ—Ä—Ö–æ–π–≥“Ø–π"],
        "body": formalized_text,
        "action_items": actions,
        "entities": entities,
        "metadata": {
            "original_text_length": len(raw_text),
            "formalized_text_length": len(formalized_text),
            "mode": "SLM-only",
            "model": "qwen2.5:7b"
        }
    }
    
    print(f"   ‚úì –ü—Ä–æ—Ç–æ–∫–æ–ª –±—ç–ª—ç–Ω:")
    print(f"      - –ì–∞—Ä—á–∏–≥: {protocol['title']}")
    print(f"      - –û–≥–Ω–æ–æ: {protocol['date']}")
    print(f"      - –û—Ä–æ–ª—Ü–æ–≥—á–∏–¥: {len(protocol['participants'])} —Ö“Ø–Ω")
    print(f"      - –ê–∂–∏–ª “Ø“Ø—Ä—ç–≥: {len(protocol['action_items'])} —à–∏—Ä—Ö—ç–≥")
    print(f"      - –†–µ–∂–∏–º: SLM-only (Fallback –±–∞–π—Ö–≥“Ø–π)")
    
    # 8. DOCX —Ñ–∞–π–ª “Ø“Ø—Å–≥—ç—Ö
    print("\n8Ô∏è‚É£  DOCX —Ñ–∞–π–ª “Ø“Ø—Å–≥—ç–∂ –±–∞–π–Ω–∞...")
    
    try:
        filename = export_enhanced_protocol(protocol)
        print(f"   ‚úì –ê–º–∂–∏–ª—Ç—Ç–∞–π: {filename}")
        
        # –§–∞–π–ª—ã–Ω —Ö—ç–º–∂—ç—ç
        file_size = Path(filename).stat().st_size
        print(f"   –§–∞–π–ª—ã–Ω —Ö—ç–º–∂—ç—ç: {file_size:,} bytes ({file_size/1024:.1f} KB)")
        
    except Exception as e:
        print(f"   ‚ùå DOCX “Ø“Ø—Å–≥—ç—Ö—ç–¥ –∞–ª–¥–∞–∞: {e}")
        return
    
    # 9. –î“Ø–≥–Ω—ç–ª—Ç
    print("\n" + "="*60)
    print("‚úÖ –¢–ï–°–¢ –ê–ú–ñ–ò–õ–¢–¢–ê–ô –î–£–£–°–õ–ê–ê!")
    print("="*60)
    print(f"\nüìÑ –ü—Ä–æ—Ç–æ–∫–æ–ª —Ñ–∞–π–ª: {filename}")
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫:")
    print(f"   - –†–µ–∂–∏–º: SLM-only (qwen2.5:7b)")
    print(f"   - –ê–Ω—Ö–Ω—ã —Ç–µ–∫—Å—Ç: {len(raw_text)} —Ç—ç–º–¥—ç–≥—Ç")
    print(f"   - –ë–æ–ª–æ–≤—Å—Ä—É—É–ª—Å–∞–Ω: {len(formalized_text)} —Ç—ç–º–¥—ç–≥—Ç")
    print(f"   - –•—É—Ä–∞–∞–Ω–≥—É–π–ª–∞–ª—Ç: {(1 - len(formalized_text)/len(raw_text))*100:.1f}%")
    print(f"   - –û–ª—Å–æ–Ω –Ω—ç—Ä—Å: {len(entities)}")
    print(f"   - –ê–∂–∏–ª “Ø“Ø—Ä—ç–≥: {len(actions)}")
    print(f"\nüí° –°–∞–Ω–∞–º–∂: SLM fallback –±–∞–π—Ö–≥“Ø–π - –∞–ª–¥–∞–∞ –≥–∞—Ä–≤–∞–ª —à—É—É–¥ –∑–æ–≥—Å–æ–Ω–æ\n")


def show_usage():
    """
    –•—ç—Ä—ç–≥–ª—ç—Ö –∑–∞–∞–≤–∞—Ä
    """
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë     –ú–û–ù–ì–û–õ –ü–†–û–¢–û–ö–û–õ “Æ“Æ–°–ì–≠–• –°–ò–°–¢–ï–ú (SLM-ONLY –†–ï–ñ–ò–ú)            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

–•—ç—Ä—ç–≥–ª—ç—Ö –∞—Ä–≥–∞:

1. JSON —Ñ–∞–π–ª–∞–∞—Å –ø—Ä–æ—Ç–æ–∫–æ–ª “Ø“Ø—Å–≥—ç—Ö:
   python test_protocol.py text.json

2. API server —ç—Ö–ª“Ø“Ø–ª—ç—Ö:
   uvicorn app.main:app --reload

3. API —Ç–µ—Å—Ç–ª—ç—Ö:
   curl -X POST http://localhost:8000/generate_protocol \\
        -H "Content-Type: application/json" \\
        -d @text.json

4. SLM —Ç”©–ª”©–≤ —à–∞–ª–≥–∞—Ö:
   curl http://localhost:8000/health

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö†Ô∏è  –ß–£–•–ê–õ: SLM-ONLY —Ä–µ–∂–∏–º
   - Fallback –ë–ê–ô–•–ì“Æ–ô
   - SLM –∞–∂–∏–ª–ª–∞—Ö–≥“Ø–π –±–æ–ª –ó–û–ì–°–û–ù–û
   - Rule-based backup –ë–ê–ô–•–ì“Æ–ô

–®–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π:
   ‚úì Python 3.8+
   ‚úì Ollama —Å—É—É–ª–≥–∞—Å–∞–Ω + –∞–∂–∏–ª–ª–∞–∂ –±–∞–π–≥–∞–∞
   ‚úì qwen2.5:7b model —Ç–∞—Ç—Å–∞–Ω
   ‚úì requirements.txt-–∏–π–Ω —Å–∞–Ω–≥—É—É–¥

SLM –±—ç–ª–¥—ç—Ö:
   1. ollama serve
   2. ollama pull qwen2.5:7b
   3. python test_protocol.py

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
""")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        arg = sys.argv[1]
        
        if arg in ['-h', '--help', 'help']:
            show_usage()
        else:
            # JSON —Ñ–∞–π–ª—ã–Ω –∑–∞–º –¥–∞–º–∂—É—É–ª—Å–∞–Ω
            test_with_json_file(arg)
    else:
        # Default: text.json –∞—à–∏–≥–ª–∞—Ö
        test_with_json_file("text.json")